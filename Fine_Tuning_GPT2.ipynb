{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine Tuning GPT2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anmaxwell/quotemaker/blob/master/Fine_Tuning_GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "#  Train a GPT-2 Text-Generating Model w/ GPU For Free \n",
        "\n",
        "Copied from notebook by [Max Woolf](http://minimaxir.com).  Max's notebook is the basis of this notebook - I just removed a couple of the additional options he put in.\n",
        "\n",
        "Retrain an advanced text generating neural network on any text dataset **for free on a GPU using Collaboratory** using `gpt-2-simple`!\n",
        "\n",
        "For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple). You can also read Max's [blog post](https://minimaxir.com/2019/09/howto-gpt2/) for more information how to use his notebook!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ead7a152-aa54-4a45-e6d6-5d756513a1d5"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS"
      },
      "source": [
        "## Downloading GPT-2\n",
        "\n",
        "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
        "\n",
        "I am using the 'smallest' model - `124M` as this is just to try out making quotes.\n",
        "\n",
        "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68f620da-5a50-4284-d4ea-6cbfcfa4e135"
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 261Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 2.06Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 389Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:16, 29.7Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 587Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 3.43Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 2.81Mit/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
        "\n",
        "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "163d2dfe-8783-4782-9098-869edb189f5f"
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory\n",
        "\n",
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
        "\n",
        "Upload **any smaller text file**  (<10 MB) and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "file_name = \"quotes.txt\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE"
      },
      "source": [
        "If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS"
      },
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
        "\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815d6ecc-90fe-4e8f-c01b-6253b733fe9d"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:05<00:00,  5.95s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 1222583 tokens\n",
            "Training...\n",
            "[10 | 28.21] loss=3.26 avg=3.26\n",
            "[20 | 50.56] loss=3.25 avg=3.26\n",
            "[30 | 73.34] loss=3.25 avg=3.25\n",
            "[40 | 96.87] loss=3.25 avg=3.25\n",
            "[50 | 121.29] loss=3.31 avg=3.26\n",
            "[60 | 145.23] loss=3.25 avg=3.26\n",
            "[70 | 168.95] loss=3.23 avg=3.26\n",
            "[80 | 192.94] loss=3.27 avg=3.26\n",
            "[90 | 217.04] loss=3.15 avg=3.25\n",
            "[100 | 241.01] loss=3.14 avg=3.24\n",
            "[110 | 264.94] loss=3.36 avg=3.25\n",
            "[120 | 288.87] loss=3.19 avg=3.24\n",
            "[130 | 312.83] loss=3.17 avg=3.24\n",
            "[140 | 336.82] loss=3.23 avg=3.24\n",
            "[150 | 360.79] loss=3.23 avg=3.23\n",
            "[160 | 384.80] loss=3.21 avg=3.23\n",
            "[170 | 408.79] loss=3.13 avg=3.23\n",
            "[180 | 432.80] loss=3.00 avg=3.21\n",
            "[190 | 456.83] loss=3.13 avg=3.21\n",
            "[200 | 480.88] loss=3.06 avg=3.20\n",
            "======== SAMPLE 1 ========\n",
            " income and education would be a great benefit to society.\n",
            "There's also an element of fantasy. It's not about where you go and what you're capable of doing. But it's about who you are and why you come here, who you're with and your future.\n",
            "The best thing I can offer you is that I think there are a fair bit of things we don't know about the World Cup because it's so difficult to know who you're going to get to and when and how to get there.\n",
            "I try to keep my faith in everything we do for the children and the grandchildren, so that people have someone to talk to who can do things for them all day, and be able to talk to about their experiences with their grandchildren.\n",
            "The beauty of it is that there is no one thing you can get away with.\n",
            "Life is not about being perfect and no matter how you act about the world, it's all about being happy.\n",
            "I think you have to put what you think is right, and you've got to do it right. I remember going into high school in Philadelphia. You had to be perfect, get good grades. Your father was a preacher, all you had to do was work, and that was the only way you could do it, the only way you could be a Christian, was to do it and then God would say, 'Do yourself a favor, and you're right there with me.'\n",
            "I had my parents back in school when I was eight or nine or 10 years old, which was the year I became a writer because I was into movies. My dad was in the Army and my mom was in marketing. So at that time, it was basically kind of something for me, and I would come home and have my mom and my dad and see what everybody else was doing.\n",
            "In this business, you have to give all the credit to the team. That's part of it. You have to have the ability to win.\n",
            "I think the only people doing TV are really good at it.\n",
            "I have my dad, my two brothers, who are really great at it as well. I have my mom.\n",
            "I did the best I was able to do, and I hope that I can do some more but I'm very happy in the industry.\n",
            "My mom did her best.\n",
            "We do not know the true nature of the life that we have. We only know ourselves and who we are.\n",
            "I never met my dad, but he was extremely kind and always gave me a lot of advice.\n",
            "I think our greatest successes come from the same people who have taught us, the most basic kind of love. It's not always the good ones in love or respect, but there the love comes.\n",
            "I love my mom dearly, but I know that I'm always going to end up being the same one. You can be so nice to someone else, but they need to let you know that you don't deserve anything. I think that's what you get in life.\n",
            "I was lucky in that my dad had the ability to direct me to something that was at all of my dreams. And I hope that when I look back at my life, I realize that I was lucky to have the opportunity.\n",
            "I've really tried to be more of a father, my mom had to say she felt like there was a very strong connection between her and my character as a dad.\n",
            "You're doing a lot of interviews and you're going to get all these interviews from all the great people. I think it's so exciting, I just got to have all these new jobs and I'm so lucky because I got to have a real dad.\n",
            "We have a problem now, as we all saw in the early 1970s, in our children's education. In part that's because a new generation of young people is not having the same opportunities with regard to reading, reading with one hand, or reading on the other. The literacy rate is way lower now than in the past and kids are more likely to have a teacher or tutor in class than they did as far back as the turn of the 20th century.\n",
            "With every new piece of technology, we learn how to recognize it and take notice.\n",
            "The great thing about playing baseball is that you're not so much a baseball player as a person. You might have the first hit to win the game and he's the one that wins the game, but he's not the one that sells it. As a player you want to be different because that's the game you want to play.\n",
            "I'm actually an emotional man.\n",
            "I don't think women have a very good chance of making friends. They can be like, 'OK, let's try being friends with another actor.'\n",
            "I think there's one thing that is really important: That I take care of my family, that I'm always out and going, that I do things for my family. What that means is I would love to go back\n",
            "\n",
            "[210 | 516.63] loss=2.97 avg=3.19\n",
            "[220 | 540.57] loss=2.99 avg=3.18\n",
            "[230 | 564.54] loss=2.86 avg=3.16\n",
            "[240 | 588.50] loss=3.04 avg=3.16\n",
            "[250 | 612.47] loss=3.19 avg=3.16\n",
            "[260 | 636.44] loss=3.06 avg=3.15\n",
            "[270 | 660.44] loss=2.90 avg=3.14\n",
            "[280 | 684.44] loss=3.04 avg=3.14\n",
            "[290 | 708.42] loss=2.97 avg=3.13\n",
            "[300 | 732.39] loss=2.94 avg=3.13\n",
            "[310 | 756.39] loss=2.94 avg=3.12\n",
            "[320 | 780.39] loss=2.88 avg=3.11\n",
            "[330 | 804.37] loss=2.89 avg=3.10\n",
            "[340 | 828.33] loss=2.89 avg=3.09\n",
            "[350 | 852.29] loss=2.94 avg=3.09\n",
            "[360 | 876.27] loss=2.81 avg=3.08\n",
            "[370 | 900.24] loss=3.04 avg=3.08\n",
            "[380 | 924.19] loss=2.76 avg=3.07\n",
            "[390 | 948.16] loss=3.07 avg=3.07\n",
            "[400 | 972.11] loss=2.77 avg=3.06\n",
            "======== SAMPLE 1 ========\n",
            " me.\n",
            "The fact that you can read a book, read a book, take a film, make a movie, make a film, get a screenplay in six hours, or write a screenplay for you at a conference, you're a beacon of hope.\n",
            "A writer has the power to make dreams a reality.\n",
            "When I got the opportunity to be part of a Broadway production of The Artist, I loved it, and I love the idea of what the experience of the performance could be. It's very exciting that I find myself as a director.\n",
            "I think most people are too busy with the family business to go to the movies now. They need jobs too. But the idea that there's the same thing going on with the movie business is very appealing to me.\n",
            "You can't put yourself in the shoes of a person without telling them the truth. It takes a lot of courage not to tell the truth.\n",
            "We are all very grateful for that opportunity to become the leaders of the world, but it's the first time in our nation's history that we've asked for it.\n",
            "No woman who does not make her living in order to make women happy and be able to say, 'I'm going to give my wife the best job I can give her' will be a great woman to have in a man.\n",
            "I'm tired of being a loser, and I can relate to that. It's great that women can be great about it, but don't it mean you don't want to be a loser? I mean, you can go on in a bad career and a lot of women won't put up with that. Do you want to be a loser? Because that's the attitude I took.\n",
            "What is the place of man who is too good an example for his peers to bear to be repeated? What is for posterity to fear?\n",
            "Women have the opportunity, and it seems to me quite a few women have the nerve to start making dreams come true. I think when people have an idea and they have confidence in your ability, then they will be ready to make those dreams a reality.\n",
            "When you are young you can be so good in everything but when you're old you look the way you need to look. It is the golden rule of working hard, being self-reliant, and trusting in your friends and your dreams.\n",
            "Dreams are only fantasies, dreams are not the outcome of experience, dreams are not reality.\n",
            "No longer is man to be worshipped in temples as a god for the sake of gods or gods for his own sake, but to be sought after by the gods in temples as a means of acquiring knowledge, wisdom and power.\n",
            "I think most of us have been here many years, we all sit at the table, talk about things we don't understand and we all work together. Then we all die and we don't have a place where we can sit and talk about it, let alone talk about why, why, why not just be a god as opposed to living in this horrible time, just a job, a home, a retirement or nothing? Where do you sit and think about how much better and more important it really is, how much better what you've got?\n",
            "When a woman's only dream is to have children, she should not have any more jobs than her husband can hire them.\n",
            "Dreams... are born of a dream and a dream are made upon the dream's memory and memory is a dream.\n",
            "I had a dream about my first horse. I had that horse in my heart. I was working for two years because of the dream of being a horse trainer when I was 12.\n",
            "I've never had any illusions about a writer of colour. If this were to happen it would probably be more of a rarity to have some kind of one-on-one talent with whom this is not a normal occurrence.\n",
            "Dreams are like water, they bring to dream and to rest, sleep and dream.\n",
            "So if you take a dream and look at it everyday, you will recognize the character of some of the characters.\n",
            "It is said that dreams are the fountain of youth and wisdom.\n",
            "Dreams often make me cry. It is a great pleasure to be able to listen on the shoulders of giants with them not speaking my language.\n",
            "Dreams of men and of kings come from dreams of women.\n",
            "I had dreams about my father. I'd go through life without him. I'd never meet his face... but he told me stories. I've never met his face.\n",
            "I think that what you are doing now has made a difference as far as how we're able to raise a child. It's brought out more happiness in a couple, and made a difference in a bunch of families.\n",
            "Our dreams are really the most important thing in our lives. They're the most important thing in human life. That's why we have a dream in our head, because otherwise a lot of people go crazy with dreams.\n",
            "I\n",
            "\n",
            "[410 | 1006.25] loss=2.71 avg=3.05\n",
            "[420 | 1030.23] loss=2.78 avg=3.04\n",
            "[430 | 1054.26] loss=2.75 avg=3.03\n",
            "[440 | 1078.30] loss=2.91 avg=3.03\n",
            "[450 | 1102.32] loss=3.00 avg=3.03\n",
            "[460 | 1126.30] loss=2.73 avg=3.02\n",
            "[470 | 1150.29] loss=2.71 avg=3.01\n",
            "[480 | 1174.26] loss=2.59 avg=3.00\n",
            "[490 | 1198.23] loss=2.69 avg=2.99\n",
            "[500 | 1222.17] loss=2.83 avg=2.99\n",
            "Saving checkpoint/run1/model-500\n",
            "[510 | 1248.63] loss=2.81 avg=2.99\n",
            "[520 | 1272.76] loss=2.93 avg=2.98\n",
            "[530 | 1296.85] loss=2.66 avg=2.98\n",
            "[540 | 1320.88] loss=2.75 avg=2.97\n",
            "[550 | 1344.88] loss=2.69 avg=2.96\n",
            "[560 | 1368.90] loss=2.91 avg=2.96\n",
            "[570 | 1392.92] loss=2.73 avg=2.96\n",
            "[580 | 1416.89] loss=2.88 avg=2.96\n",
            "[590 | 1440.88] loss=2.75 avg=2.95\n",
            "[600 | 1464.85] loss=2.61 avg=2.94\n",
            "======== SAMPLE 1 ========\n",
            " of my dreams.\n",
            "Dreams should be made up of things we can't really see, for example dreams are the dreams of the past, and dreams are like dreams, and dreams are like dreams.\n",
            "It took a bit of courage for me to realize what I've been dreaming about for too long. But, look, I'm lucky to be alive and have a lot of dreams.\n",
            "I just try to dream about dreams for years.\n",
            "You can do whatever you want with your life. You're not allowed to take a life of your own. If you want to do something, make a dream-based choice.\n",
            "Some of my best dreams came true on 'Mad Men,' where I got a very young Matt Damon.\n",
            "I think all my dreams have happened, and that's great. The things I dream and think have all come true.\n",
            "I was dreaming that the future of the United States would be determined by a President we should choose from a Cabinet of thoughtful government men who would find the Constitution and our laws, and preserve the rights and privileges enjoyed by every man, citizen and small business, an immutable and solid law.\n",
            "I want to live forever. I want to die forever. I want to fight in this world for the dreams that are missing, the dreams that are lacking.\n",
            "I just want to be able to dream, and just go out there and play the guitar and do whatever I'm good at, and I don't have any obligations that I don't have with other people who work in the industry and have a stake in this.\n",
            "I really like the challenge of getting back into the music business. I enjoy the fact that I can be around people and share my dreams with them.\n",
            "My work ethic and my passion for the dream have been my strength, not my limitations.\n",
            "Dreams of a future without a past are just fantasies.\n",
            "I had a chance to meet and meet and talk to a couple of girls who wanted to start their own careers, and they were interested. I'd love to start working as an actress, but that's tough for me. I just wanna do my best to do my best to do my best.\n",
            "I love dreams, really, I love dreams.\n",
            "I'm happy to do what I can for one person, one dream - but at the same time, I want to make it possible for people, all across the country, to make it their dream in their own community. We're a melting pot, which is a lot to ask for, especially in the wake of the tragedy at the hands of so many good people!\n",
            "The dream has always been to make a movie that people who don't know much about will not enjoy. To have a bad ending will be a huge disappointment.\n",
            "I hope I'm not mistaken that the first person the audience sees is my wife, my mom and my sister-in-law. And that means the audience. I mean, your mom's like a sister-in-law. And my sister-in-law's like a rock star.\n",
            "All the people who have dreams have dreams. And they also need to be ready for life to get a little bit tougher. But you know, I want to keep going.\n",
            "I am more excited about living in the future or the past than I ever was just running a stock exchange. I love the idea that now we can have a future.\n",
            "The fact that we have a government that doesn't want people to have a sense of their dreams and dreams and dreams - and I mean that - is the definition of tyranny.\n",
            "One of the most interesting things, as far as I'm concerned, is seeing if a woman who's doing well is in any way a success in her life or a failure in her dreams. I'd love to see her try to change the world.\n",
            "What's the first thing you ever want to do is create a big band, and all of a sudden, that band has become the biggest band in the world, and it's your own, and it's your own business. And suddenly it's something that you have been doing, which is a huge inspiration. And you want to make sure that it's awesome, that it's fun and that you're all in the right together.\n",
            "I just get on and I give the fans everything I accomplished in my life.\n",
            "As the Obama campaign said at the time, he was a Christian, and his campaign said they don't know whether he believed that. But on the campaign trail, Obama said they're going to find out when he's really into this business, which makes him a little unusual.\n",
            "Well, all I want has been the opportunity to work hard and to have the dreams of the future in my future.\n",
            "I don't have a plan for where I'm going, what my future could be, where I might be, or what my future is. But, I want to keep the dreams for the future alive.\n",
            "Sometimes all you need to do is watch what\n",
            "\n",
            "[610 | 1499.27] loss=2.70 avg=2.94\n",
            "[620 | 1523.24] loss=2.74 avg=2.93\n",
            "[630 | 1547.20] loss=2.69 avg=2.93\n",
            "[640 | 1571.15] loss=2.51 avg=2.92\n",
            "[650 | 1595.09] loss=2.56 avg=2.91\n",
            "[660 | 1619.04] loss=2.33 avg=2.90\n",
            "[670 | 1642.97] loss=2.89 avg=2.90\n",
            "[680 | 1666.93] loss=2.47 avg=2.89\n",
            "[690 | 1690.88] loss=2.37 avg=2.88\n",
            "[700 | 1714.84] loss=2.60 avg=2.88\n",
            "[710 | 1738.80] loss=2.56 avg=2.87\n",
            "[720 | 1762.75] loss=2.66 avg=2.87\n",
            "[730 | 1786.70] loss=2.59 avg=2.86\n",
            "[740 | 1810.63] loss=2.45 avg=2.85\n",
            "[750 | 1834.55] loss=2.58 avg=2.85\n",
            "[760 | 1858.46] loss=2.41 avg=2.84\n",
            "[770 | 1882.37] loss=2.29 avg=2.83\n",
            "[780 | 1906.30] loss=2.29 avg=2.82\n",
            "[790 | 1930.23] loss=2.50 avg=2.81\n",
            "[800 | 1954.20] loss=2.38 avg=2.81\n",
            "======== SAMPLE 1 ========\n",
            " own, they become part of our life.\n",
            "The beauty and richness of the sea, the highlands, the forests, the forests of the imagination, the forests of the mind, The imagination seizes up all the imagination, and makes it real, and makes it real all round the window!\n",
            "The thing the imagination has in mind is the consciousness of its own limitations and imperatives, and of its own nature and function.\n",
            "The power of the imagination in the conception and intensification of reality.\n",
            "When we begin to understand the origin of the human mind, it is brought into being because the great imagination is the human mind.\n",
            "An artist needs a great imagination.\n",
            "The imagination is the first limit of human experience.\n",
            "You can't tell the difference between a good joke and a bad joke.\n",
            "I have the freedom to be a big old white cat.\n",
            "The imagination is the great mother of poetry.\n",
            "When you're young, what can you want to think? All my experience seems to show me that life is infinite.\n",
            "Life's no better than a world of imagination and imagination, a world of desires and fears and dreams, a world of laughter and tragedy.\n",
            "L. R. was the great rebel who told the whole history of the Negro, and made it known.\n",
            "The mind is a wonderful object, a tool of the soul, a great instrument of the manipulation of mood, of perception - of imagination, of thought.\n",
            "A man of imagination and wisdom, who finds in the contemplation of this world of literature a sort of sublime satisfaction, with the world of imagination, a kind of sublime realization.\n",
            "The imagination is the mother of art, and it alone can furnish a fine education.\n",
            "The man who has the capacity to see the world, to relate his own soul to it, can see only what other man thinks.\n",
            "If the human intellect be imitated, that the whole soul is imitated, and that we may make all the intelligible intelligible.\n",
            "The imagination is a very large and splendid object, the very thing it is supposed to protect against, and is so under the impression that it cannot bear it.\n",
            "I am one who has lived under the influence of dreams and whose imagination takes me outside from the present world.\n",
            "The most important and powerful thing I have learned about creativity is that you can give away a lot of your imagination just for this cause.\n",
            "In every act of imagination a part of the body appears, and acts of imagination appear separate parts of the body.\n",
            "If one's heart, and imagination, has no power then one must never, never work with a machine, an instrument of a race.\n",
            "The imagination is never without hope.\n",
            "The most important of all the gifts is the ability to move beyond the reality of what is imagined. This is what dreamers have to offer.\n",
            "If you cannot think beyond the reality of what is imagined, you won't get there unless you imaginatively imagine it. The only way you will get there is by moving beyond the reality of what is imagined.\n",
            "We need to think the imagination, rather than the facts of facts, and we need to think the nature of the artist, rather than the processes of nature, and we need to think the nature of art rather than the expression of art.\n",
            "The imagination is a very large and splendid object, the very thing it is supposed to protect against, and is so under the impression that it cannot bear it.\n",
            "I don't believe in life's being guided by any single thought. Imagination is life's driving power. That's what allows us to escape from us all our problems.\n",
            "What is the secret to a great literary work? Imagination and knowledge. But, man does, after all, become acquainted with his objects in his dreams.\n",
            "A man of the senses is useful only against dreamers. In a dream, he is either asleep or asleep.\n",
            "To the man of this world, and to the whole of eternity, what is it that we wish to do? Imagination is one of the greatest blessings of all the blessings bestowed by the age. It enables man to see to the very edge of his vision.\n",
            "Man cannot learn that he can understand, that he could create and that he can make others what he wants them to be. His imagination allows him to see the end in his dream and the whole order, the whole thing, at a single moment of time. A man of great experience is capable of this, but what he may not see, can make him believe.\n",
            "If you work, if you read, or if you make a mistake, you will never be alone. This is the great truth. It takes a small circle of people to lift the veil of anonymity. Those who dare to make it will be attacked all the more fiercely than the foes of a little imagination.\n",
            "I never saw any man of intelligence but after the confusion of youth. No man of learning succeeds who has lost the ability to look ahead. So a man\n",
            "\n",
            "[810 | 1988.21] loss=2.20 avg=2.79\n",
            "[820 | 2012.16] loss=2.37 avg=2.79\n",
            "[830 | 2036.14] loss=2.44 avg=2.78\n",
            "[840 | 2060.17] loss=2.67 avg=2.78\n",
            "[850 | 2084.20] loss=2.09 avg=2.77\n",
            "[860 | 2108.20] loss=2.43 avg=2.76\n",
            "[870 | 2132.19] loss=2.39 avg=2.75\n",
            "[880 | 2156.17] loss=2.56 avg=2.75\n",
            "[890 | 2180.14] loss=1.94 avg=2.74\n",
            "[900 | 2204.09] loss=2.66 avg=2.74\n",
            "[910 | 2228.02] loss=2.28 avg=2.73\n",
            "[920 | 2251.94] loss=2.47 avg=2.72\n",
            "[930 | 2275.88] loss=2.33 avg=2.72\n",
            "[940 | 2299.86] loss=2.57 avg=2.72\n",
            "[950 | 2323.84] loss=2.47 avg=2.71\n",
            "[960 | 2347.87] loss=2.03 avg=2.70\n",
            "[970 | 2371.91] loss=2.34 avg=2.69\n",
            "[980 | 2395.97] loss=2.29 avg=2.69\n",
            "[990 | 2420.04] loss=2.34 avg=2.68\n",
            "[1000 | 2444.11] loss=2.18 avg=2.67\n",
            "Saving checkpoint/run1/model-1000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXSuTNERaw6K"
      },
      "source": [
        "After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n",
        "\n",
        "If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. The checkpoint folder is copied as a `.rar` compressed file; you can download it and uncompress it locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3"
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV"
      },
      "source": [
        "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "997a6df0-7853-42e6-9fe7-fa4a093c4763"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/run1/model-1000\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a26e2f12-cbf4-42f8-8e5e-afa63af7588c"
      },
      "source": [
        "gpt2.generate(sess, run_name='run1')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I've always said that one way I can get out of a bad situation is to quit it. That can be an absolute death sentence. For me, that's the only way out of a bad situation.\n",
            "Households are not going to pay more in gasoline or electricity. The money they currently have to use the utilities they own now costs them much more than they did before the Great Recession hit.\n",
            "In America, I'm not the poster child for energy efficiency. But I'm the poster boy for energy conservation.\n",
            "I don't think that we are on the verge of a climate catastrophe because we continue to expand our oil and gas industry despite a $4.7 billion deficit, huge budget deficits and a $1.2 billion budget deficit in the third quarter.\n",
            "If you're a McDonald's customer, you know that there's nothing better or more fun than finding a fast food place to eat in your home. One of the things that McDonald's does is they take their customers and give them a reason to stay, to stay and go, and that's what we do.\n",
            "If you're a McDonald's customer, you know that there's nothing better or more fun than finding a fast food place to eat in your home. One of the things that McDonald's does is they take their customers and give them a reason to stay, to stay and go.\n",
            "We have two acres of wilderness in the County of Columbia and one acre of wilderness in the County of Columbia. The people have lived in it for 150 years. And they all agree that it is the most arid and dangerous place in the Union.\n",
            "I'm an American, and I understand the importance of health. And I'm not going to turn back to a standard diet and sugar, fat, and exercising, any more.\n",
            "I think we've come to a place where we have to be concerned about the food we eat. We're not going to be able to afford to feed our children with nothing but salt, we're not going to be able to afford to feed our kids with nothing but soy.\n",
            "I grew up in a hugely arid place, and I'm not going to talk about it. But I'm going to say that the lack of water and sanitation has made it very hard on the people, the animals, to make their own way into the outdoors.\n",
            "We have to understand the food and the environment issues there.\n",
            "I'm an advocate of an all-of-the-above approach. I believe what works best for the environment is a sustainable food system that takes into account the needs of the planet, the food supply and the people.\n",
            "We need a sustainable energy system where we can make sure that we don't allow the oil and gas industry to take away our jobs.\n",
            "Some of the things that I think are important are environmental issues: we need to need to limit the spread of diseases, we need to address the causes of cancer, we need to address the causes of heart disease.\n",
            "I don't believe in government taking environmental issues into account when setting environmental policies.\n",
            "Energy and food are two different things.\n",
            "I think we're going to try to have environmental policies that are in line with some of the things we see in the world, like the need to help the developing world.\n",
            "I don't like the way the media portray things in terms of the things that are important in the world. I think it's really important for people to know that we all care about these things and that we all fight for them.\n",
            "In terms of my experiences and what I have learned, I think it's very important for kids to know that they're going to have a chance to make an impact on the world and help change the world.\n",
            "Environmental regulations and the permitting process are a tremendous burden on small businesses.\n",
            "My mother was very practical and very open about her goals. She was willing to accept whatever was difficult for her and to put her energy and experience into whatever she was going to do.\n",
            "We used to go to the mall and buy expensive clothes. Now we only buy cheap shoes. We don't understand how regulations work.\n",
            "I'm a big believer in making things differently. I think ecology and environmental justice are important issues, and I think there are lots of things I'd like to do. I'd like to do something like the Clean Water Act, so that we don't pollute the oceans with our waste products.\n",
            "The environmental impact of a hotel is often being ignored by the major food manufacturers, and it is even being ignored by the U.S. dairy industry.\n",
            "I'm amazed at the amount of attention that we've been paying to water and food and the environment.\n",
            "The timing of the Paris Agreement is unfortunate. It is not good for the climate and food systems because we have an economic and environmental system that is being driven down the drain by. Now we're dealing with an agreement that is also horribly damaging to people's health.\n",
            "The environmental impact of nuclear power plants is being ignored\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R"
      },
      "source": [
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
        "\n",
        "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
        "\n",
        "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
        "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
        "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c862fdae-fb36-4a2a-88ad-64fd927fc985"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              length=100,\n",
        "              temperature=0.7,\n",
        "              truncate='.',\n",
        "              nsamples=15,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I'm going to give you all a piece of my mind\n",
            "====================\n",
            "What does that mean? What does that mean? You can't have a revolution unless you have a revolution\n",
            "====================\n",
            "I think that the only way that we can really change is to change the culture\n",
            "====================\n",
            "The light is blue and the darkness is gray\n",
            "====================\n",
            "For my birthday, I got an old poster of 'The Art of Happiness' and I couldn't believe it\n",
            "====================\n",
            "I am a very shy person\n",
            "====================\n",
            "I saved money on clothes and car payments by buying a house and moving out\n",
            "====================\n",
            "The idea of a nation that believes in free markets and creative innovation, with a focus on education and innovation, is the prudent course\n",
            "====================\n",
            "I'm just a normal kid, but I can't wait to have my own apartment\n",
            "====================\n",
            "The debate over abortion has reached a cross-partisan cross-country cross-country cross-country cross-country cross-country point of view\n",
            "====================\n",
            "I am really happy living in a civilization where beauty is not a luxury\n",
            "====================\n",
            "The full meaning of life is at stake when you decide to engage in the most radical changes in the pursuit of that ideal\n",
            "====================\n",
            "The thing I remember most about 'Aquaman' is that I always had this thing about myself or other characters being invisible or indestructible and it made me feel invisible\n",
            "====================\n",
            "I am having the best day ever\n",
            "====================\n",
            "I think that it's scary\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-KVgkCDCKD"
      },
      "source": [
        "# Etcetera\n",
        "\n",
        "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHiVP53FnsX"
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTXWNUygS5E"
      },
      "source": [
        "# LICENSE\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2019 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}